{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffc3ca5",
   "metadata": {},
   "source": [
    "# Parsing the Code\n",
    "\n",
    "To learn more about how Earth Engine users interact with different datasets and modules, we'll have to start digging further into source code by parsing each file, line-by-line to look for patterns. This script will do the heavy lifting of parsing our code, saving the results out to CSVs for further analysis and visualization in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcaf3d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:10:17.868467Z",
     "start_time": "2022-03-06T04:10:17.791531Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84cb87",
   "metadata": {},
   "source": [
    "## Load Repos and Source Files\n",
    "\n",
    "First, we need to re-load our list of source files like we did in the Summarizing Code notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acda7fba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:14:24.513797Z",
     "start_time": "2022-03-06T04:11:09.663857Z"
    }
   },
   "outputs": [],
   "source": [
    "directory_path = os.path.join(\"..\", \"data\", \"directory.json\")\n",
    "\n",
    "with open(directory_path) as src:\n",
    "    directory = json.load(src)\n",
    "\n",
    "repos = list(directory.keys())\n",
    "\n",
    "repo_dir = os.path.join(\"..\", \"data\", \"repos\")\n",
    "repo_paths = [os.path.join(repo_dir, repo) for repo in repos]\n",
    "\n",
    "# Filter out missing and empty repos\n",
    "invalid_repos = [repo for repo in repo_paths if not os.path.exists(repo) or os.listdir(repo) == []]\n",
    "\n",
    "valid_repos = [repo for repo in repo_paths if repo not in invalid_repos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb02606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:14:40.966253Z",
     "start_time": "2022-03-06T04:14:40.963154Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_source_files(directory):\n",
    "    \"\"\"Find all the files that are probably Earth Engine source code in a given directory.\n",
    "    Files should have no extension or .js extension, not be included in a hidden directory\n",
    "    like .git, and not be in a list of commonly excluded files.\n",
    "    \n",
    "    This function also renames all non-js source files to .js to\n",
    "    allow code analysis later on.\n",
    "    \"\"\"\n",
    "    # Common non-source files that might be included in a repository and don't have a file extension.\n",
    "    exclude_files = [\"LICENSE\"]\n",
    "                     \n",
    "    # List all files and folders recursively, excluding hidden stuff (e.g. .git)\n",
    "    everything = glob.glob(os.path.join(directory, \"**\", \"*\"), recursive=True)\n",
    "    \n",
    "    source_files = []\n",
    "    for file in everything:\n",
    "        # Exclude subdirectories\n",
    "        if not os.path.isfile(file):\n",
    "            continue\n",
    "        # Exclude specific files\n",
    "        if os.path.basename(file) in exclude_files:\n",
    "            continue\n",
    "        # Exclude any filetypes other than JS\n",
    "        if \".\" in file and not file.endswith(\".js\"):\n",
    "            continue\n",
    "        # Add .js extension to all source files for later analysis\n",
    "        if not file.endswith(\".js\"):\n",
    "            os.rename(file, file + \".js\")\n",
    "            file = file + \".js\"\n",
    "        \n",
    "        source_files.append(file)\n",
    "        \n",
    "    return source_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d7d2c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:18:07.033553Z",
     "start_time": "2022-03-06T04:14:42.210972Z"
    }
   },
   "outputs": [],
   "source": [
    "source_files = []\n",
    "\n",
    "for repo in valid_repos:\n",
    "    source_files += get_source_files(repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819f928",
   "metadata": {},
   "source": [
    "## Parse the Code\n",
    "\n",
    "Now we can start looking through individual source code files for specific patterns to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91bd116d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:18:38.754625Z",
     "start_time": "2022-03-06T04:18:38.752921Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597b04e",
   "metadata": {},
   "source": [
    "We'll need a function that can take a module name or a file path and parse out the username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e14c347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:18:39.137013Z",
     "start_time": "2022-03-06T04:18:39.130620Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_user(s):\n",
    "    \"\"\"Take a path-like string and return the username associated\"\"\"\n",
    "    user_pattern = r\"\"\"users\\/([a-zA-Z]*[0-9]*)\\/\"\"\"\n",
    "    try:\n",
    "        return re.findall(user_pattern, s)[0]\n",
    "    # A few repos don't have a username\n",
    "    except IndexError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82c52a",
   "metadata": {},
   "source": [
    "We'll use the regex patterns below to parse source code and see how often datasets, modules, and other parameters are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18ea9afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:18:48.226788Z",
     "start_time": "2022-03-06T04:18:48.220773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Match image collection names\n",
    "collection_pattern = re.compile(r\"\"\"ee\\.ImageCollection\\(['\"](\\S+?)['\"]\\)\\.?\"\"\")\n",
    "# Match image names\n",
    "image_pattern = re.compile(r\"\"\"ee\\.Image\\(['\"](\\S+?)['\"]\\)\\.?\"\"\")\n",
    "# Match latitude and longitude coordinates from ee.Geometry.Point constructors\n",
    "point_pattern = re.compile(r\"\"\"ee\\.Geometry\\.Point\\((\\[[^a-zA-Z]*?\\])\\)\\.?\"\"\")\n",
    "\n",
    "# Match CRS parameters\n",
    "crs_pattern = re.compile(r\"\"\"crs:\\s*['\"]([a-zA-Z]{4}:[0-9]{4})['\"]\"\"\")\n",
    "# Match module imports\n",
    "module_pattern = re.compile(r\"\"\"require\\(['\"](\\S+?)['\"]\\)\"\"\")\n",
    "# Match dates of the format yyyy-mm-dd\n",
    "date_pattern = re.compile(r\"\"\"([0-9]{4}-[0-9]{2}-[0-9]{2})\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7bbff",
   "metadata": {},
   "source": [
    "Iterate over every line of every source code file and count unique datasets, modules, etc. This takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505a2d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-06T04:22:25.689Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to run?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84e8371f55143558d9b2233c47813ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing:   0%|          | 0/213393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input(\"Are you sure you want to run?\")\n",
    "\n",
    "collections = Counter()\n",
    "images = Counter()\n",
    "crs = Counter()\n",
    "modules = Counter()\n",
    "points = []\n",
    "dates = Counter()\n",
    "\n",
    "for file in tqdm(source_files, desc=\"Parsing\"):\n",
    "    try:\n",
    "        file_user = get_user(file)\n",
    "        with open(file, encoding=\"utf-8\") as src:\n",
    "            for line in src:\n",
    "                collection_match = collection_pattern.search(line)\n",
    "                if collection_match:\n",
    "                    collections.update([collection_match.group(1)])\n",
    "                    \n",
    "                image_match = image_pattern.search(line)\n",
    "                if image_match:\n",
    "                    images.update([image_match.group(1)])\n",
    "                \n",
    "                crs_match = crs_pattern.search(line)\n",
    "                if crs_match:\n",
    "                    crs.update([crs_match.group(1)])\n",
    "\n",
    "                point_match = point_pattern.search(line)\n",
    "                if point_match:\n",
    "                    points.append(point_match.group(1))\n",
    "\n",
    "                module_match = module_pattern.search(line)\n",
    "                if module_match:\n",
    "                    mod = module_match.group(1)\n",
    "                    # Filter out when a user requires their own modules\n",
    "                    if get_user(mod) != file_user:\n",
    "                        modules.update([mod])\n",
    "                        \n",
    "                date_match = date_pattern.search(line)\n",
    "                if date_match:\n",
    "                    dates.update([date_match.group(1)])\n",
    "\n",
    "    # A very small number of files aren't readable. Skip those.\n",
    "    except UnicodeDecodeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c5852",
   "metadata": {},
   "source": [
    "## Export Raw Data\n",
    "\n",
    "Since it took a while to process this data, let's save it to disk for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19ead235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:43:45.906995Z",
     "start_time": "2022-03-06T04:43:44.772879Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575254e",
   "metadata": {},
   "source": [
    "Export a dataframe showing the number of imports for each collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3bfcdfb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T01:56:52.479319Z",
     "start_time": "2022-03-05T01:56:52.463769Z"
    }
   },
   "outputs": [],
   "source": [
    "collection_df = pd.DataFrame.from_dict(collections, orient=\"index\").reset_index().rename(columns={\"index\": \"collection\", 0: \"imports\"})\n",
    "collection_df.to_csv(os.path.join(\"..\", \"data\", \"collections.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ff960",
   "metadata": {},
   "source": [
    "Export a dataframe showing the number of imports for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bb0aa7ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T01:57:41.563093Z",
     "start_time": "2022-03-05T01:57:41.455897Z"
    }
   },
   "outputs": [],
   "source": [
    "images_df = pd.DataFrame.from_dict(images, orient=\"index\").reset_index().rename(columns={\"index\": \"image\", 0: \"imports\"})\n",
    "images_df.to_csv(os.path.join(\"..\", \"data\", \"images.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3d3b0",
   "metadata": {},
   "source": [
    "Export a dataframe showing the number of imports for each module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "25df735a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T01:57:44.830706Z",
     "start_time": "2022-03-05T01:57:44.823513Z"
    }
   },
   "outputs": [],
   "source": [
    "modules_df = pd.DataFrame.from_dict(modules, orient=\"index\").reset_index().rename(columns={\"index\": \"module\", 0: \"imports\"})\n",
    "modules_df.to_csv(os.path.join(\"..\", \"data\", \"modules.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88795c28",
   "metadata": {},
   "source": [
    "Export a dataframe showing the number of time each date was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67fa7a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T04:43:48.915522Z",
     "start_time": "2022-03-06T04:43:48.900693Z"
    }
   },
   "outputs": [],
   "source": [
    "dates_df = pd.DataFrame.from_dict(dates, orient=\"index\").reset_index().rename(columns={\"index\": \"date\", 0: \"used\"})\n",
    "dates_df.to_csv(os.path.join(\"..\", \"data\", \"dates.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee9404",
   "metadata": {},
   "source": [
    "Convert all the CRS codes to upper case, re-count them, and export a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "69d9505c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T06:36:36.998046Z",
     "start_time": "2022-03-05T06:36:36.979475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all CRS's to uppercase.\n",
    "c = Counter()\n",
    "for k, v in crs.items():\n",
    "    c.update({k.upper(): v})\n",
    "    \n",
    "crs_df = pd.DataFrame.from_dict(c, orient=\"index\").reset_index().rename(columns={\"index\": \"crs\", 0: \"exports\"})\n",
    "crs_df.to_csv(os.path.join(\"..\", \"data\", \"crs.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b28da9",
   "metadata": {},
   "source": [
    "Parse the point coordinates to geometries and export as a geopackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7c5d7fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T06:10:49.796417Z",
     "start_time": "2022-03-05T06:10:26.938304Z"
    }
   },
   "outputs": [],
   "source": [
    "point_geoms = []\n",
    "\n",
    "coord_pattern = r\"\"\"^\\[['\"]*?\\s*?(\\s?[\\-0-9.]+)\\s*?,\\s*?([\\-0-9.]+)\\s*?['\"]*?\\]\"\"\"\n",
    "\n",
    "for point in set(points):\n",
    "    match = re.search(coord_pattern, point)\n",
    "    try:\n",
    "        lng, lat = match.group(1, 2)\n",
    "        try:\n",
    "            lng = float(lng)\n",
    "            lat = float(lat)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if lng < -180 or lng > 180 or lat < -180 or lat > 180:\n",
    "            continue\n",
    "        point_geoms.append(Point([float(lng), float(lat)]))\n",
    "        \n",
    "    # So many syntax errors!\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "pt_gdf = gpd.GeoDataFrame(geometry=point_geoms, crs=\"EPSG:4326\")\n",
    "pt_gdf.to_file(os.path.join(\"..\", \"data\", \"points.gpkg\"), driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eestats]",
   "language": "python",
   "name": "conda-env-eestats-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
